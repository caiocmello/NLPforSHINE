{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import urllib.request\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change variables here\n",
    "\n",
    "year = '2012'\n",
    "domain = '%22guardian.co.uk%22' \n",
    "domain_name = 'guardian'\n",
    "topic = '%22Olympic+Legacy%22'\n",
    "\n",
    "# determine how many files need to be downloaded\n",
    "NumberOfPages = 'X'\n",
    "X = 10294\n",
    "pageCount = X/10\n",
    "pageCount = math.ceil(pageCount)\n",
    "\n",
    "startValue = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURL(page):\n",
    "    \"\"\"\n",
    "\n",
    "    :param page: html of web page (here: Python home page) \n",
    "    :return: urls in that page \n",
    "    \"\"\"\n",
    "    start_link = page.find(\"a href\")\n",
    "    if start_link == -1:\n",
    "        return None, 0\n",
    "    start_quote = page.find('\"', start_link)\n",
    "    end_quote = page.find('\"', start_quote + 1)\n",
    "    url = page[start_quote + 1: end_quote]\n",
    "    return url, end_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "local = './data/' + year + '/' + domain_name\n",
    "filename = year + domain + 'search'\n",
    "\n",
    "urllist = []\n",
    "\n",
    "for pages in range(1, pageCount +1):\n",
    "\n",
    "    # each part of the URL. Slipt up to be easier to read.\n",
    "\n",
    "    url = 'https://www.webarchive.org.uk/shine/search?query='    \n",
    "    url += topic # query\n",
    "    url += '&page='\n",
    "    url += str(startValue) # page number\n",
    "    url += '&facet.in.domain='\n",
    "    url += domain\n",
    "    url += '&tab=results&action=search&mode=&facet.in.crawl_year='\n",
    "    url += year\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # parse html\n",
    "\n",
    "    page = str(BeautifulSoup(response.content))\n",
    "\n",
    "    while True:\n",
    "        url, n = getURL(page)\n",
    "        page = page[n:]\n",
    "        if url:\n",
    "            urllist.append(url)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    startValue = startValue + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(local, filename + '.txt'), 'w+') as urllistfile:\n",
    "    urllistfile.write('\\n'.join(urllist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------- STOP HERE-----------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
